{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Temp\\ipykernel_6324\\3096108358.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x0000021A7150D790>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07000935, -0.01570813,  0.05609965, ...,  0.05186507,\n",
       "         0.0039544 , -0.03760503],\n",
       "       [-0.0374433 ,  0.02414865, -0.04913577, ..., -0.00071819,\n",
       "        -0.07389734, -0.07403124],\n",
       "       [ 0.01045132, -0.02342552, -0.01363755, ..., -0.03862363,\n",
       "         0.07259874,  0.06267877],\n",
       "       ...,\n",
       "       [ 0.05183624,  0.03152754, -0.06924748, ..., -0.00107355,\n",
       "         0.05507182, -0.02244285],\n",
       "       [-0.04077723, -0.0498422 , -0.03065461, ..., -0.05667526,\n",
       "        -0.05628294, -0.03612458],\n",
       "       [ 0.05347902, -0.07288817,  0.03784343, ..., -0.03681912,\n",
       "         0.01385988, -0.05467883]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biases)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784 * 300 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235500\n"
     ]
    }
   ],
   "source": [
    "# 1º neurona de la 1º hidden layer\n",
    "# y = a + w1*x1 + w2*x2 + .... wn*xn\n",
    "# a es el intercepto llamado bias\n",
    "# wn es cada uno de los pesos que va a ir actualizando con el backpropagation\n",
    "# n es 784\n",
    "# En la 1º hidden layer tenemos 784 pesos por cada neurona, al tener 300, tenemos un total de:\n",
    "print(784*300 + 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 784 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 100 + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * 10 + 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.125"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.3995 - accuracy: 0.6704 - val_loss: 0.7731 - val_accuracy: 0.8365\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.5857 - accuracy: 0.8635 - val_loss: 0.4956 - val_accuracy: 0.8693\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4349 - accuracy: 0.8871 - val_loss: 0.4164 - val_accuracy: 0.8848\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3774 - accuracy: 0.8985 - val_loss: 0.3762 - val_accuracy: 0.8936\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3440 - accuracy: 0.9054 - val_loss: 0.3506 - val_accuracy: 0.9004\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3210 - accuracy: 0.9108 - val_loss: 0.3327 - val_accuracy: 0.9041\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3029 - accuracy: 0.9157 - val_loss: 0.3173 - val_accuracy: 0.9084\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2883 - accuracy: 0.9195 - val_loss: 0.3036 - val_accuracy: 0.9133\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2757 - accuracy: 0.9224 - val_loss: 0.2924 - val_accuracy: 0.9167\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2644 - accuracy: 0.9255 - val_loss: 0.2857 - val_accuracy: 0.9185\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2544 - accuracy: 0.9280 - val_loss: 0.2742 - val_accuracy: 0.9216\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2454 - accuracy: 0.9308 - val_loss: 0.2664 - val_accuracy: 0.9242\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2370 - accuracy: 0.9337 - val_loss: 0.2590 - val_accuracy: 0.9251\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2288 - accuracy: 0.9361 - val_loss: 0.2553 - val_accuracy: 0.9259\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2218 - accuracy: 0.9377 - val_loss: 0.2472 - val_accuracy: 0.9277\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2153 - accuracy: 0.9398 - val_loss: 0.2408 - val_accuracy: 0.9288\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2085 - accuracy: 0.9422 - val_loss: 0.2365 - val_accuracy: 0.9306\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2025 - accuracy: 0.9433 - val_loss: 0.2331 - val_accuracy: 0.9311\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1968 - accuracy: 0.9454 - val_loss: 0.2304 - val_accuracy: 0.9307\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1916 - accuracy: 0.9462 - val_loss: 0.2228 - val_accuracy: 0.9329\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1864 - accuracy: 0.9475 - val_loss: 0.2177 - val_accuracy: 0.9346\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1814 - accuracy: 0.9489 - val_loss: 0.2152 - val_accuracy: 0.9354\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1766 - accuracy: 0.9499 - val_loss: 0.2108 - val_accuracy: 0.9373\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1724 - accuracy: 0.9514 - val_loss: 0.2065 - val_accuracy: 0.9386\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1681 - accuracy: 0.9527 - val_loss: 0.2078 - val_accuracy: 0.9370\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1640 - accuracy: 0.9537 - val_loss: 0.1998 - val_accuracy: 0.9399\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1600 - accuracy: 0.9548 - val_loss: 0.1982 - val_accuracy: 0.9399\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1562 - accuracy: 0.9558 - val_loss: 0.1939 - val_accuracy: 0.9421\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1527 - accuracy: 0.9572 - val_loss: 0.1919 - val_accuracy: 0.9412\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1491 - accuracy: 0.9584 - val_loss: 0.1888 - val_accuracy: 0.9429\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1459 - accuracy: 0.9595 - val_loss: 0.1862 - val_accuracy: 0.9444\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1426 - accuracy: 0.9600 - val_loss: 0.1838 - val_accuracy: 0.9446\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1396 - accuracy: 0.9610 - val_loss: 0.1791 - val_accuracy: 0.9463\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1365 - accuracy: 0.9622 - val_loss: 0.1793 - val_accuracy: 0.9452\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1336 - accuracy: 0.9628 - val_loss: 0.1759 - val_accuracy: 0.9470\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1310 - accuracy: 0.9636 - val_loss: 0.1752 - val_accuracy: 0.9471\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1280 - accuracy: 0.9650 - val_loss: 0.1705 - val_accuracy: 0.9498\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1257 - accuracy: 0.9650 - val_loss: 0.1711 - val_accuracy: 0.9495\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1230 - accuracy: 0.9655 - val_loss: 0.1679 - val_accuracy: 0.9497\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1204 - accuracy: 0.9671 - val_loss: 0.1680 - val_accuracy: 0.9493\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1183 - accuracy: 0.9672 - val_loss: 0.1660 - val_accuracy: 0.9504\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1159 - accuracy: 0.9679 - val_loss: 0.1612 - val_accuracy: 0.9513\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1135 - accuracy: 0.9689 - val_loss: 0.1610 - val_accuracy: 0.9510\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1113 - accuracy: 0.9695 - val_loss: 0.1592 - val_accuracy: 0.9505\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1093 - accuracy: 0.9698 - val_loss: 0.1585 - val_accuracy: 0.9519\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1071 - accuracy: 0.9707 - val_loss: 0.1563 - val_accuracy: 0.9525\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1054 - accuracy: 0.9713 - val_loss: 0.1547 - val_accuracy: 0.9535\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1034 - accuracy: 0.9717 - val_loss: 0.1523 - val_accuracy: 0.9542\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1013 - accuracy: 0.9726 - val_loss: 0.1506 - val_accuracy: 0.9547\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0997 - accuracy: 0.9729 - val_loss: 0.1500 - val_accuracy: 0.9550\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 0.9370 - accuracy: 0.7746 - val_loss: 0.4908 - val_accuracy: 0.8657\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.4079 - accuracy: 0.8905 - val_loss: 0.3760 - val_accuracy: 0.8914\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.3345 - accuracy: 0.9071 - val_loss: 0.3328 - val_accuracy: 0.9026\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.2967 - accuracy: 0.9167 - val_loss: 0.3034 - val_accuracy: 0.9124\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.2703 - accuracy: 0.9238 - val_loss: 0.2827 - val_accuracy: 0.9176\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.2488 - accuracy: 0.9298 - val_loss: 0.2641 - val_accuracy: 0.9226\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.2314 - accuracy: 0.9345 - val_loss: 0.2501 - val_accuracy: 0.9290\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.2165 - accuracy: 0.9392 - val_loss: 0.2401 - val_accuracy: 0.9304\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.2029 - accuracy: 0.9424 - val_loss: 0.2270 - val_accuracy: 0.9328\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.1911 - accuracy: 0.9458 - val_loss: 0.2208 - val_accuracy: 0.9355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21a7fdc22d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [1.3994892835617065, 0.585737943649292, 0.4348529875278473, 0.37741267681121826, 0.34403035044670105, 0.3209538459777832, 0.302896648645401, 0.2882995307445526, 0.27568113803863525, 0.2643889784812927, 0.2544366717338562, 0.24537797272205353, 0.23700793087482452, 0.22884821891784668, 0.22181475162506104, 0.21527627110481262, 0.20853191614151, 0.20250873267650604, 0.19681386649608612, 0.1915588229894638, 0.18637056648731232, 0.18140378594398499, 0.17663323879241943, 0.172371968626976, 0.16808755695819855, 0.1640390008687973, 0.16004252433776855, 0.15621067583560944, 0.15268008410930634, 0.1490810364484787, 0.14592358469963074, 0.14260746538639069, 0.1395752727985382, 0.1364753246307373, 0.13363954424858093, 0.13098451495170593, 0.1279985010623932, 0.12567581236362457, 0.12303094565868378, 0.12042186409235, 0.11827375739812851, 0.11585959792137146, 0.11353785544633865, 0.11134776473045349, 0.10925804078578949, 0.10712197422981262, 0.10535434633493423, 0.10336808860301971, 0.10132617503404617, 0.0997348427772522], 'accuracy': [0.6703749895095825, 0.8634750247001648, 0.8870999813079834, 0.8985000252723694, 0.9053750038146973, 0.9107999801635742, 0.9157000184059143, 0.9195250272750854, 0.9224249720573425, 0.9255499839782715, 0.9279999732971191, 0.9307500123977661, 0.9337249994277954, 0.93607497215271, 0.9377250075340271, 0.9398249983787537, 0.9421749711036682, 0.9433000087738037, 0.9453750252723694, 0.9461749792098999, 0.947475016117096, 0.9489250183105469, 0.9498999714851379, 0.951449990272522, 0.9526749849319458, 0.9537000060081482, 0.9548249840736389, 0.9557999968528748, 0.9571750164031982, 0.9583749771118164, 0.9595000147819519, 0.959975004196167, 0.9610000252723694, 0.9622250199317932, 0.9628499746322632, 0.963575005531311, 0.9649500250816345, 0.9649749994277954, 0.9654750227928162, 0.9671249985694885, 0.967199981212616, 0.9678750038146973, 0.968874990940094, 0.9695000052452087, 0.969825029373169, 0.9707000255584717, 0.9713249802589417, 0.9717249870300293, 0.9726499915122986, 0.9728749990463257], 'val_loss': [0.7730954885482788, 0.4955926835536957, 0.41641679406166077, 0.37620604038238525, 0.35063380002975464, 0.33272916078567505, 0.3173114061355591, 0.3036435544490814, 0.2923758327960968, 0.28567081689834595, 0.27421674132347107, 0.26641133427619934, 0.25900620222091675, 0.2553064823150635, 0.24717922508716583, 0.24083611369132996, 0.23650331795215607, 0.23307864367961884, 0.23043417930603027, 0.22284841537475586, 0.217743918299675, 0.21523351967334747, 0.2108388990163803, 0.20650771260261536, 0.20778577029705048, 0.19979968667030334, 0.198248490691185, 0.19393344223499298, 0.19193145632743835, 0.18876725435256958, 0.18621233105659485, 0.18376800417900085, 0.17905017733573914, 0.17925438284873962, 0.17586570978164673, 0.1752391904592514, 0.17053727805614471, 0.17114046216011047, 0.1678909808397293, 0.1680106222629547, 0.16599708795547485, 0.1611596941947937, 0.1609671413898468, 0.15915414690971375, 0.1585431545972824, 0.15626047551631927, 0.154734805226326, 0.1522689312696457, 0.1506245881319046, 0.150028795003891], 'val_accuracy': [0.8364999890327454, 0.8693000078201294, 0.8848000168800354, 0.8935999870300293, 0.9003999829292297, 0.9041000008583069, 0.9083999991416931, 0.9132999777793884, 0.916700005531311, 0.9185000061988831, 0.9215999841690063, 0.9241999983787537, 0.9251000285148621, 0.9258999824523926, 0.9276999831199646, 0.9287999868392944, 0.9305999875068665, 0.9311000108718872, 0.9307000041007996, 0.9329000115394592, 0.9345999956130981, 0.9354000091552734, 0.9373000264167786, 0.9386000037193298, 0.9369999766349792, 0.9398999810218811, 0.9398999810218811, 0.9420999884605408, 0.9412000179290771, 0.9429000020027161, 0.9444000124931335, 0.944599986076355, 0.9463000297546387, 0.9452000260353088, 0.9470000267028809, 0.9470999836921692, 0.9498000144958496, 0.9495000243186951, 0.9496999979019165, 0.9492999911308289, 0.9503999948501587, 0.9513000249862671, 0.9509999752044678, 0.9505000114440918, 0.9519000053405762, 0.9524999856948853, 0.953499972820282, 0.954200029373169, 0.9546999931335449, 0.9549999833106995]}\n"
     ]
    }
   ],
   "source": [
    "# print(history.params)\n",
    "# print(history.epoch)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.3994892835617065,\n",
       "  0.585737943649292,\n",
       "  0.4348529875278473,\n",
       "  0.37741267681121826,\n",
       "  0.34403035044670105,\n",
       "  0.3209538459777832,\n",
       "  0.302896648645401,\n",
       "  0.2882995307445526,\n",
       "  0.27568113803863525,\n",
       "  0.2643889784812927,\n",
       "  0.2544366717338562,\n",
       "  0.24537797272205353,\n",
       "  0.23700793087482452,\n",
       "  0.22884821891784668,\n",
       "  0.22181475162506104,\n",
       "  0.21527627110481262,\n",
       "  0.20853191614151,\n",
       "  0.20250873267650604,\n",
       "  0.19681386649608612,\n",
       "  0.1915588229894638,\n",
       "  0.18637056648731232,\n",
       "  0.18140378594398499,\n",
       "  0.17663323879241943,\n",
       "  0.172371968626976,\n",
       "  0.16808755695819855,\n",
       "  0.1640390008687973,\n",
       "  0.16004252433776855,\n",
       "  0.15621067583560944,\n",
       "  0.15268008410930634,\n",
       "  0.1490810364484787,\n",
       "  0.14592358469963074,\n",
       "  0.14260746538639069,\n",
       "  0.1395752727985382,\n",
       "  0.1364753246307373,\n",
       "  0.13363954424858093,\n",
       "  0.13098451495170593,\n",
       "  0.1279985010623932,\n",
       "  0.12567581236362457,\n",
       "  0.12303094565868378,\n",
       "  0.12042186409235,\n",
       "  0.11827375739812851,\n",
       "  0.11585959792137146,\n",
       "  0.11353785544633865,\n",
       "  0.11134776473045349,\n",
       "  0.10925804078578949,\n",
       "  0.10712197422981262,\n",
       "  0.10535434633493423,\n",
       "  0.10336808860301971,\n",
       "  0.10132617503404617,\n",
       "  0.0997348427772522],\n",
       " 'accuracy': [0.6703749895095825,\n",
       "  0.8634750247001648,\n",
       "  0.8870999813079834,\n",
       "  0.8985000252723694,\n",
       "  0.9053750038146973,\n",
       "  0.9107999801635742,\n",
       "  0.9157000184059143,\n",
       "  0.9195250272750854,\n",
       "  0.9224249720573425,\n",
       "  0.9255499839782715,\n",
       "  0.9279999732971191,\n",
       "  0.9307500123977661,\n",
       "  0.9337249994277954,\n",
       "  0.93607497215271,\n",
       "  0.9377250075340271,\n",
       "  0.9398249983787537,\n",
       "  0.9421749711036682,\n",
       "  0.9433000087738037,\n",
       "  0.9453750252723694,\n",
       "  0.9461749792098999,\n",
       "  0.947475016117096,\n",
       "  0.9489250183105469,\n",
       "  0.9498999714851379,\n",
       "  0.951449990272522,\n",
       "  0.9526749849319458,\n",
       "  0.9537000060081482,\n",
       "  0.9548249840736389,\n",
       "  0.9557999968528748,\n",
       "  0.9571750164031982,\n",
       "  0.9583749771118164,\n",
       "  0.9595000147819519,\n",
       "  0.959975004196167,\n",
       "  0.9610000252723694,\n",
       "  0.9622250199317932,\n",
       "  0.9628499746322632,\n",
       "  0.963575005531311,\n",
       "  0.9649500250816345,\n",
       "  0.9649749994277954,\n",
       "  0.9654750227928162,\n",
       "  0.9671249985694885,\n",
       "  0.967199981212616,\n",
       "  0.9678750038146973,\n",
       "  0.968874990940094,\n",
       "  0.9695000052452087,\n",
       "  0.969825029373169,\n",
       "  0.9707000255584717,\n",
       "  0.9713249802589417,\n",
       "  0.9717249870300293,\n",
       "  0.9726499915122986,\n",
       "  0.9728749990463257],\n",
       " 'val_loss': [0.7730954885482788,\n",
       "  0.4955926835536957,\n",
       "  0.41641679406166077,\n",
       "  0.37620604038238525,\n",
       "  0.35063380002975464,\n",
       "  0.33272916078567505,\n",
       "  0.3173114061355591,\n",
       "  0.3036435544490814,\n",
       "  0.2923758327960968,\n",
       "  0.28567081689834595,\n",
       "  0.27421674132347107,\n",
       "  0.26641133427619934,\n",
       "  0.25900620222091675,\n",
       "  0.2553064823150635,\n",
       "  0.24717922508716583,\n",
       "  0.24083611369132996,\n",
       "  0.23650331795215607,\n",
       "  0.23307864367961884,\n",
       "  0.23043417930603027,\n",
       "  0.22284841537475586,\n",
       "  0.217743918299675,\n",
       "  0.21523351967334747,\n",
       "  0.2108388990163803,\n",
       "  0.20650771260261536,\n",
       "  0.20778577029705048,\n",
       "  0.19979968667030334,\n",
       "  0.198248490691185,\n",
       "  0.19393344223499298,\n",
       "  0.19193145632743835,\n",
       "  0.18876725435256958,\n",
       "  0.18621233105659485,\n",
       "  0.18376800417900085,\n",
       "  0.17905017733573914,\n",
       "  0.17925438284873962,\n",
       "  0.17586570978164673,\n",
       "  0.1752391904592514,\n",
       "  0.17053727805614471,\n",
       "  0.17114046216011047,\n",
       "  0.1678909808397293,\n",
       "  0.1680106222629547,\n",
       "  0.16599708795547485,\n",
       "  0.1611596941947937,\n",
       "  0.1609671413898468,\n",
       "  0.15915414690971375,\n",
       "  0.1585431545972824,\n",
       "  0.15626047551631927,\n",
       "  0.154734805226326,\n",
       "  0.1522689312696457,\n",
       "  0.1506245881319046,\n",
       "  0.150028795003891],\n",
       " 'val_accuracy': [0.8364999890327454,\n",
       "  0.8693000078201294,\n",
       "  0.8848000168800354,\n",
       "  0.8935999870300293,\n",
       "  0.9003999829292297,\n",
       "  0.9041000008583069,\n",
       "  0.9083999991416931,\n",
       "  0.9132999777793884,\n",
       "  0.916700005531311,\n",
       "  0.9185000061988831,\n",
       "  0.9215999841690063,\n",
       "  0.9241999983787537,\n",
       "  0.9251000285148621,\n",
       "  0.9258999824523926,\n",
       "  0.9276999831199646,\n",
       "  0.9287999868392944,\n",
       "  0.9305999875068665,\n",
       "  0.9311000108718872,\n",
       "  0.9307000041007996,\n",
       "  0.9329000115394592,\n",
       "  0.9345999956130981,\n",
       "  0.9354000091552734,\n",
       "  0.9373000264167786,\n",
       "  0.9386000037193298,\n",
       "  0.9369999766349792,\n",
       "  0.9398999810218811,\n",
       "  0.9398999810218811,\n",
       "  0.9420999884605408,\n",
       "  0.9412000179290771,\n",
       "  0.9429000020027161,\n",
       "  0.9444000124931335,\n",
       "  0.944599986076355,\n",
       "  0.9463000297546387,\n",
       "  0.9452000260353088,\n",
       "  0.9470000267028809,\n",
       "  0.9470999836921692,\n",
       "  0.9498000144958496,\n",
       "  0.9495000243186951,\n",
       "  0.9496999979019165,\n",
       "  0.9492999911308289,\n",
       "  0.9503999948501587,\n",
       "  0.9513000249862671,\n",
       "  0.9509999752044678,\n",
       "  0.9505000114440918,\n",
       "  0.9519000053405762,\n",
       "  0.9524999856948853,\n",
       "  0.953499972820282,\n",
       "  0.954200029373169,\n",
       "  0.9546999931335449,\n",
       "  0.9549999833106995]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.399489</td>\n",
       "      <td>0.670375</td>\n",
       "      <td>0.773095</td>\n",
       "      <td>0.8365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585738</td>\n",
       "      <td>0.863475</td>\n",
       "      <td>0.495593</td>\n",
       "      <td>0.8693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.434853</td>\n",
       "      <td>0.887100</td>\n",
       "      <td>0.416417</td>\n",
       "      <td>0.8848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.377413</td>\n",
       "      <td>0.898500</td>\n",
       "      <td>0.376206</td>\n",
       "      <td>0.8936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.344030</td>\n",
       "      <td>0.905375</td>\n",
       "      <td>0.350634</td>\n",
       "      <td>0.9004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.320954</td>\n",
       "      <td>0.910800</td>\n",
       "      <td>0.332729</td>\n",
       "      <td>0.9041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.302897</td>\n",
       "      <td>0.915700</td>\n",
       "      <td>0.317311</td>\n",
       "      <td>0.9084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.288300</td>\n",
       "      <td>0.919525</td>\n",
       "      <td>0.303644</td>\n",
       "      <td>0.9133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.275681</td>\n",
       "      <td>0.922425</td>\n",
       "      <td>0.292376</td>\n",
       "      <td>0.9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.264389</td>\n",
       "      <td>0.925550</td>\n",
       "      <td>0.285671</td>\n",
       "      <td>0.9185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.254437</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.274217</td>\n",
       "      <td>0.9216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.245378</td>\n",
       "      <td>0.930750</td>\n",
       "      <td>0.266411</td>\n",
       "      <td>0.9242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.237008</td>\n",
       "      <td>0.933725</td>\n",
       "      <td>0.259006</td>\n",
       "      <td>0.9251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.228848</td>\n",
       "      <td>0.936075</td>\n",
       "      <td>0.255306</td>\n",
       "      <td>0.9259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.221815</td>\n",
       "      <td>0.937725</td>\n",
       "      <td>0.247179</td>\n",
       "      <td>0.9277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.215276</td>\n",
       "      <td>0.939825</td>\n",
       "      <td>0.240836</td>\n",
       "      <td>0.9288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.208532</td>\n",
       "      <td>0.942175</td>\n",
       "      <td>0.236503</td>\n",
       "      <td>0.9306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.202509</td>\n",
       "      <td>0.943300</td>\n",
       "      <td>0.233079</td>\n",
       "      <td>0.9311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.196814</td>\n",
       "      <td>0.945375</td>\n",
       "      <td>0.230434</td>\n",
       "      <td>0.9307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.191559</td>\n",
       "      <td>0.946175</td>\n",
       "      <td>0.222848</td>\n",
       "      <td>0.9329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.186371</td>\n",
       "      <td>0.947475</td>\n",
       "      <td>0.217744</td>\n",
       "      <td>0.9346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.181404</td>\n",
       "      <td>0.948925</td>\n",
       "      <td>0.215234</td>\n",
       "      <td>0.9354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.176633</td>\n",
       "      <td>0.949900</td>\n",
       "      <td>0.210839</td>\n",
       "      <td>0.9373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.172372</td>\n",
       "      <td>0.951450</td>\n",
       "      <td>0.206508</td>\n",
       "      <td>0.9386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.168088</td>\n",
       "      <td>0.952675</td>\n",
       "      <td>0.207786</td>\n",
       "      <td>0.9370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.164039</td>\n",
       "      <td>0.953700</td>\n",
       "      <td>0.199800</td>\n",
       "      <td>0.9399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.160043</td>\n",
       "      <td>0.954825</td>\n",
       "      <td>0.198248</td>\n",
       "      <td>0.9399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.156211</td>\n",
       "      <td>0.955800</td>\n",
       "      <td>0.193933</td>\n",
       "      <td>0.9421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.152680</td>\n",
       "      <td>0.957175</td>\n",
       "      <td>0.191931</td>\n",
       "      <td>0.9412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.149081</td>\n",
       "      <td>0.958375</td>\n",
       "      <td>0.188767</td>\n",
       "      <td>0.9429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.145924</td>\n",
       "      <td>0.959500</td>\n",
       "      <td>0.186212</td>\n",
       "      <td>0.9444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.142607</td>\n",
       "      <td>0.959975</td>\n",
       "      <td>0.183768</td>\n",
       "      <td>0.9446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.139575</td>\n",
       "      <td>0.961000</td>\n",
       "      <td>0.179050</td>\n",
       "      <td>0.9463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.136475</td>\n",
       "      <td>0.962225</td>\n",
       "      <td>0.179254</td>\n",
       "      <td>0.9452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.133640</td>\n",
       "      <td>0.962850</td>\n",
       "      <td>0.175866</td>\n",
       "      <td>0.9470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.130985</td>\n",
       "      <td>0.963575</td>\n",
       "      <td>0.175239</td>\n",
       "      <td>0.9471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.127999</td>\n",
       "      <td>0.964950</td>\n",
       "      <td>0.170537</td>\n",
       "      <td>0.9498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.125676</td>\n",
       "      <td>0.964975</td>\n",
       "      <td>0.171140</td>\n",
       "      <td>0.9495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.123031</td>\n",
       "      <td>0.965475</td>\n",
       "      <td>0.167891</td>\n",
       "      <td>0.9497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.120422</td>\n",
       "      <td>0.967125</td>\n",
       "      <td>0.168011</td>\n",
       "      <td>0.9493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.118274</td>\n",
       "      <td>0.967200</td>\n",
       "      <td>0.165997</td>\n",
       "      <td>0.9504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.115860</td>\n",
       "      <td>0.967875</td>\n",
       "      <td>0.161160</td>\n",
       "      <td>0.9513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.113538</td>\n",
       "      <td>0.968875</td>\n",
       "      <td>0.160967</td>\n",
       "      <td>0.9510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.111348</td>\n",
       "      <td>0.969500</td>\n",
       "      <td>0.159154</td>\n",
       "      <td>0.9505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.109258</td>\n",
       "      <td>0.969825</td>\n",
       "      <td>0.158543</td>\n",
       "      <td>0.9519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.107122</td>\n",
       "      <td>0.970700</td>\n",
       "      <td>0.156260</td>\n",
       "      <td>0.9525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.105354</td>\n",
       "      <td>0.971325</td>\n",
       "      <td>0.154735</td>\n",
       "      <td>0.9535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.103368</td>\n",
       "      <td>0.971725</td>\n",
       "      <td>0.152269</td>\n",
       "      <td>0.9542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.101326</td>\n",
       "      <td>0.972650</td>\n",
       "      <td>0.150625</td>\n",
       "      <td>0.9547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.099735</td>\n",
       "      <td>0.972875</td>\n",
       "      <td>0.150029</td>\n",
       "      <td>0.9550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   1.399489  0.670375  0.773095        0.8365\n",
       "1   0.585738  0.863475  0.495593        0.8693\n",
       "2   0.434853  0.887100  0.416417        0.8848\n",
       "3   0.377413  0.898500  0.376206        0.8936\n",
       "4   0.344030  0.905375  0.350634        0.9004\n",
       "5   0.320954  0.910800  0.332729        0.9041\n",
       "6   0.302897  0.915700  0.317311        0.9084\n",
       "7   0.288300  0.919525  0.303644        0.9133\n",
       "8   0.275681  0.922425  0.292376        0.9167\n",
       "9   0.264389  0.925550  0.285671        0.9185\n",
       "10  0.254437  0.928000  0.274217        0.9216\n",
       "11  0.245378  0.930750  0.266411        0.9242\n",
       "12  0.237008  0.933725  0.259006        0.9251\n",
       "13  0.228848  0.936075  0.255306        0.9259\n",
       "14  0.221815  0.937725  0.247179        0.9277\n",
       "15  0.215276  0.939825  0.240836        0.9288\n",
       "16  0.208532  0.942175  0.236503        0.9306\n",
       "17  0.202509  0.943300  0.233079        0.9311\n",
       "18  0.196814  0.945375  0.230434        0.9307\n",
       "19  0.191559  0.946175  0.222848        0.9329\n",
       "20  0.186371  0.947475  0.217744        0.9346\n",
       "21  0.181404  0.948925  0.215234        0.9354\n",
       "22  0.176633  0.949900  0.210839        0.9373\n",
       "23  0.172372  0.951450  0.206508        0.9386\n",
       "24  0.168088  0.952675  0.207786        0.9370\n",
       "25  0.164039  0.953700  0.199800        0.9399\n",
       "26  0.160043  0.954825  0.198248        0.9399\n",
       "27  0.156211  0.955800  0.193933        0.9421\n",
       "28  0.152680  0.957175  0.191931        0.9412\n",
       "29  0.149081  0.958375  0.188767        0.9429\n",
       "30  0.145924  0.959500  0.186212        0.9444\n",
       "31  0.142607  0.959975  0.183768        0.9446\n",
       "32  0.139575  0.961000  0.179050        0.9463\n",
       "33  0.136475  0.962225  0.179254        0.9452\n",
       "34  0.133640  0.962850  0.175866        0.9470\n",
       "35  0.130985  0.963575  0.175239        0.9471\n",
       "36  0.127999  0.964950  0.170537        0.9498\n",
       "37  0.125676  0.964975  0.171140        0.9495\n",
       "38  0.123031  0.965475  0.167891        0.9497\n",
       "39  0.120422  0.967125  0.168011        0.9493\n",
       "40  0.118274  0.967200  0.165997        0.9504\n",
       "41  0.115860  0.967875  0.161160        0.9513\n",
       "42  0.113538  0.968875  0.160967        0.9510\n",
       "43  0.111348  0.969500  0.159154        0.9505\n",
       "44  0.109258  0.969825  0.158543        0.9519\n",
       "45  0.107122  0.970700  0.156260        0.9525\n",
       "46  0.105354  0.971325  0.154735        0.9535\n",
       "47  0.103368  0.971725  0.152269        0.9542\n",
       "48  0.101326  0.972650  0.150625        0.9547\n",
       "49  0.099735  0.972875  0.150029        0.9550"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1239 - accuracy: 0.9625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.123934805393219, 0.9624999761581421]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Temp\\ipykernel_6324\\1468152043.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.006, 0.   , 0.   , 0.   , 0.993, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1])\n",
    "print(predictions.shape)\n",
    "np.round(predictions,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Temp\\ipykernel_6324\\4029188365.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[1].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[1].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 963,    0,    2,    2,    1,    2,    7,    2,    1,    0],\n",
       "       [   0, 1121,    3,    1,    1,    1,    4,    1,    3,    0],\n",
       "       [   7,    1,  999,    2,    5,    0,    4,    6,    7,    1],\n",
       "       [   0,    0,   12,  969,    0,    7,    0,   10,   10,    2],\n",
       "       [   1,    0,    6,    1,  948,    0,    4,    2,    2,   18],\n",
       "       [   9,    1,    0,   18,    3,  833,   11,    1,   10,    6],\n",
       "       [   8,    3,    0,    1,    4,    6,  929,    1,    6,    0],\n",
       "       [   1,    8,   16,    5,    2,    1,    0,  981,    0,   14],\n",
       "       [   4,    0,    4,    9,    5,    6,    9,    7,  927,    3],\n",
       "       [   6,    6,    2,    8,   16,    5,    1,    8,    2,  955]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix(y_test, model.predict(X_test).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.98      0.97       980\n",
      "         1.0       0.98      0.99      0.99      1135\n",
      "         2.0       0.96      0.97      0.96      1032\n",
      "         3.0       0.95      0.96      0.96      1010\n",
      "         4.0       0.96      0.97      0.96       982\n",
      "         5.0       0.97      0.93      0.95       892\n",
      "         6.0       0.96      0.97      0.96       958\n",
      "         7.0       0.96      0.95      0.96      1028\n",
      "         8.0       0.96      0.95      0.95       974\n",
      "         9.0       0.96      0.95      0.95      1009\n",
      "\n",
      "    accuracy                           0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(X_test).argmax(axis=1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 0.8406 - val_loss: 1.2811\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.0670 - val_loss: 0.6855\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4990 - val_loss: 0.4656\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4458 - val_loss: 0.4254\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4261 - val_loss: 0.4081\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4143 - val_loss: 0.3986\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4045 - val_loss: 0.3895\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3974 - val_loss: 0.3820\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3899 - val_loss: 0.3873\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3856 - val_loss: 0.3716\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3805 - val_loss: 0.3685\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3755 - val_loss: 0.3652\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3732 - val_loss: 0.3618\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3686 - val_loss: 0.3662\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3668 - val_loss: 0.3656\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3640 - val_loss: 0.3552\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3626 - val_loss: 0.3556\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3578 - val_loss: 0.3546\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3563 - val_loss: 0.3544\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3544 - val_loss: 0.3840\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301 (1.18 KB)\n",
      "Trainable params: 301 (1.18 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3778\n",
      "0.3777638077735901\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 140ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9235085],\n",
       "       [0.473468 ],\n",
       "       [2.5334735],\n",
       "       [3.074718 ],\n",
       "       [1.7595313]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3535\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3567\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3495\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3473\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3452\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3432\n",
      "Epoch 7/30\n",
      "152/363 [===========>..................] - ETA: 0s - loss: 0.3303"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m checkpoint_cb \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1798\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1796\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1797\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 1798\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1799\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m         ):\n\u001b[0;32m   1806\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1411\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1411\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1412\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1413\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1416\u001b[0m )\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:689\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    690\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    691\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:839\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \n\u001b[0;32m    832\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;124;03m  The value of the variable.\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 839\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:818\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    816\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 818\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    821\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    822\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    823\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[0;32m    824\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[0;32m    825\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    826\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:808\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    807\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m--> 808\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:535\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    534\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 535\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    538\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3411 - val_loss: 0.3405\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3403 - val_loss: 0.3489\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3374 - val_loss: 0.3395\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3367 - val_loss: 0.3356\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3360 - val_loss: 0.3323\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3325 - val_loss: 0.3378\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3336 - val_loss: 0.3382\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3383 - val_loss: 0.8515\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=50,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb, checkpoint_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
